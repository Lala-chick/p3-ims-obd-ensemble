{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:58.944902Z",
     "start_time": "2021-04-22T11:06:56.623974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.5.0+cu101\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla V100-PCIE-32GB\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Pretrained Model\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# torchvision Models\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.171980Z",
     "start_time": "2021-04-22T11:06:59.167952Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 20  # Mini-batch size\n",
    "num_epochs = 40\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.446510Z",
     "start_time": "2021-04-22T11:06:59.443508Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.139668Z",
     "start_time": "2021-04-22T11:07:00.575728Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of super categories: 11\n",
      "Number of categories: 11\n",
      "Number of annotations: 21116\n",
      "Number of images: 2617\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.394832Z",
     "start_time": "2021-04-22T11:07:04.141668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.439837Z",
     "start_time": "2021-04-22T11:07:04.425804Z"
    }
   },
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)\n",
    "\n",
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        self.mask_image=[]\n",
    "        self.mask_label=[]\n",
    "\n",
    "        if (self.mode in ('train', 'val')):\n",
    "            print(f'{self.mode} : Preprocessing...')\n",
    "            for index in tqdm(range(len(self.coco.getImgIds()))):\n",
    "                # dataset이 index되어 list처럼 동작\n",
    "                image_id = self.coco.getImgIds(imgIds=index)\n",
    "                image_infos = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "                anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "                # Load the categories in a variable\n",
    "                cat_ids = self.coco.getCatIds()\n",
    "                cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "                # masks : size가 (height x width)인 2D\n",
    "                # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "                # Background = 0\n",
    "                masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "                # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "                for i in range(len(anns)):\n",
    "                    className = get_classname(anns[i]['category_id'], cats)\n",
    "                    pixel_value = category_names.index(className)\n",
    "                    masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "                masks = masks.astype(np.float32)\n",
    "                if 10.0 in list(np.unique(masks)): self.mask_label.append(0)\n",
    "                elif 1.0 in list(np.unique(masks)): self.mask_label.append(1)\n",
    "                elif 11.0 in list(np.unique(masks)): self.mask_label.append(2)\n",
    "                elif 6.0 in list(np.unique(masks)): self.mask_label.append(3)\n",
    "                elif 5.0 in list(np.unique(masks)): self.mask_label.append(4)\n",
    "                elif 4.0 in list(np.unique(masks)): self.mask_label.append(5)\n",
    "                elif 8.0 in list(np.unique(masks)): self.mask_label.append(6)\n",
    "                elif 7.0 in list(np.unique(masks)): self.mask_label.append(7)\n",
    "                elif 2.0 in list(np.unique(masks)): self.mask_label.append(8)\n",
    "                elif 3.0 in list(np.unique(masks)): self.mask_label.append(9)\n",
    "                elif 9.0 in list(np.unique(masks)): self.mask_label.append(10)\n",
    "                else: self.mask_label.append(11)  \n",
    "                self.mask_image.append(masks)\n",
    "\n",
    "          \n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            masks=self.mask_image[index]\n",
    "            weak_label=self.mask_label[index]\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, weak_label, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:09.179806Z",
     "start_time": "2021-04-22T11:07:04.440804Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Normalize(\n",
    "                                mean=(0.485, 0.456, 0.406),\n",
    "                                std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0\n",
    "                            ),\n",
    "                            ToTensorV2(),\n",
    "                           ])\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = ['./saved/0_checkpoint.pt',\n",
    "                './saved/1_checkpoint.pt',\n",
    "                './saved/2_checkpoint.pt',\n",
    "                './saved/3_checkpoint.pt',\n",
    "                './saved/4_checkpoint.pt']\n",
    "\n",
    "OUT_MASKS = f'./saved/test_masks.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(models, imgs, device):\n",
    "    outs = None\n",
    "    flip_outs = None\n",
    "    flips = [[-1],[-2],[-2,-1]]\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        if outs == None:\n",
    "            outs = model(imgs.to(device).float()).detach()\n",
    "        else:\n",
    "            outs += model(imgs.to(device).float()).detach()\n",
    "        \n",
    "    outs /= len(models)\n",
    "        \n",
    "    for flip in flips:\n",
    "        flip_img = torch.flip(imgs, flip)\n",
    "        tmp_outs = None\n",
    "        for model in models:\n",
    "            flip_out = model(flip_img.to(device).float()).detach()\n",
    "            flip_out = torch.flip(flip_out, flip)\n",
    "            if tmp_outs == None:\n",
    "                tmp_outs = flip_out\n",
    "            else:\n",
    "                tmp_outs += flip_out\n",
    "        tmp_outs /= len(models)\n",
    "        if flip_outs == None:\n",
    "            flip_outs = tmp_outs\n",
    "        else:\n",
    "            flip_outs += tmp_outs\n",
    "    flip_outs /= 3\n",
    "    \n",
    "    outs += flip_outs\n",
    "    \n",
    "    return outs/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader), position=0, leave=True)\n",
    "    with torch.no_grad():\n",
    "        with zipfile.ZipFile(OUT_MASKS, 'w') as mask_out:\n",
    "            for step, (imgs, image_infos) in pbar:\n",
    "                # print(imgs)\n",
    "                # print(imgs)\n",
    "                imgs = torch.stack(imgs)\n",
    "\n",
    "                outs = inference(models, imgs, device)\n",
    "\n",
    "                oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "                \n",
    "                file_name = image_infos[0]['file_name'].split(\"/\")\n",
    "                file_name[0] += \"_masks\"\n",
    "                file_name[1] = file_name[1][:-4]\n",
    "                file_name = \"/\".join(file_name)\n",
    "\n",
    "                m = cv2.imencode(\".png\", oms.squeeze())[1]\n",
    "                mask_out.writestr(f\"{file_name}.png\", m)\n",
    "\n",
    "                # resize (256 x 256)\n",
    "                temp_mask = []\n",
    "                for img, mask in zip(np.stack(imgs), oms):\n",
    "                    # print(mask.shape)\n",
    "                    transformed = transform(image=img, mask=mask)\n",
    "                    mask = transformed['mask']\n",
    "                    temp_mask.append(mask)\n",
    "\n",
    "                oms = np.array(temp_mask)\n",
    "                oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "\n",
    "                preds_array = np.vstack((preds_array, oms))\n",
    "\n",
    "                file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "for path in MODEL_PATHS:\n",
    "    model = smp.DeepLabV3Plus('resnext50_32x4d', encoder_weights=None, classes=12)\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "    \n",
    "    del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39340423fa54cef8f0c6f419f6f7f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n"
     ]
    }
   ],
   "source": [
    "file_names, preds = test(models, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:45:42.235310Z",
     "start_time": "2021-04-16T19:44:30.499016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission/Kfold_TTA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
