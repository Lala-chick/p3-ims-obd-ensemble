{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trash_seg_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "543ad93940fe4818aba0b61fd76a18e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85b0960742da4c73982950e8b30afd78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_868c3e5eb2d34112b31b0f1d4551504c",
              "IPY_MODEL_60fcd8187ac4446bad51c0dacd1afb26"
            ]
          }
        },
        "85b0960742da4c73982950e8b30afd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "868c3e5eb2d34112b31b0f1d4551504c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2a45ba369f0e4f1190798d79a4762420",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 196466866,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 196466866,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f61bbd87adba4532bbfb33ce907e5520"
          }
        },
        "60fcd8187ac4446bad51c0dacd1afb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a470d78f21954d4e8f3dd99c4aadd52c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 187M/187M [09:12&lt;00:00, 356kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eebf27e1ad0b49dcb7a98ebb67bbf800"
          }
        },
        "2a45ba369f0e4f1190798d79a4762420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f61bbd87adba4532bbfb33ce907e5520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a470d78f21954d4e8f3dd99c4aadd52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eebf27e1ad0b49dcb7a98ebb67bbf800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZx9ELQBJT-E",
        "outputId": "fb19231d-4f2a-4e27-db44-57fb07866497"
      },
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install -q -U albumentations\n",
        "!pip install timm\n",
        "!pip install adamp\n",
        "!pip install neptune-client\n",
        "# !pip install git+https://github.com/zhanghang1989/PyTorch-Encoding.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 30kB 22.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 51kB 14.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 61kB 14.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.9.1+cu101)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting timm==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 17.7MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.8.1+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision>=0.3.0->segmentation_models_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=d798b8728675da454ea703c2edf6c274cd1e3d33ca0f608cba8ae8e1fc4eb82f\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=da95d549d87a11dac0697c3c75d40c3e6bcd3b49de0619beeb567bbfbb0d76ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built pretrainedmodels efficientnet-pytorch\n",
            "Installing collected packages: munch, pretrainedmodels, timm, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 6.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37.6MB 136kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 952kB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Collecting adamp\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/56/182b8c93f18feb0244b83f9b2eff1c6b036c04d4c3880e8d222750b0d5e5/adamp-0.3.0.tar.gz\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-cp37-none-any.whl size=5999 sha256=f982856377b90f925155350ae3e487a3e5370e18e521418a199b63dca6f4d8af\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/89/67/879fe55977ebcbfaa5b929eb111af7fe11eb3552867850dd76\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n",
            "Collecting neptune-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/d9/9cb3b43a99e84f40803981f88b4d1ff781e775d9140abb22dfe378a5846b/neptune-client-0.9.5.tar.gz (211kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215kB 13.3MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client>=0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 8.9MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (20.9)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 57.6MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.7.4.3)\n",
            "Collecting bravado-core>=5.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Collecting jsonref\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting webcolors; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Collecting rfc3987; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n",
            "Collecting strict-rfc3339; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n",
            "Building wheels for collected packages: neptune-client, future, strict-rfc3339\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.9.5-py2.py3-none-any.whl size=372957 sha256=eff9bc75fab24073138176a716049faa42f6dcc6627ee3c6f9965263a4a0a0b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/b1/b8/42228d4e6f34bde7de247c8adcb64fa58c890bed5491e2ec8a\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=9f8dab73bae8a714d054e7f41a285eb8c37e597868aa930ba6e3aa81443f9735\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp37-none-any.whl size=18121 sha256=563f13bc4cafad9afc056ac80149e3dcf80463e3953037a017106fa6861f9b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n",
            "Successfully built neptune-client future strict-rfc3339\n",
            "Installing collected packages: simplejson, monotonic, jsonref, swagger-spec-validator, bravado-core, bravado, future, PyJWT, websocket-client, smmap, gitdb, GitPython, neptune-client, webcolors, rfc3987, strict-rfc3339\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.14 PyJWT-2.1.0 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jsonref-0.2 monotonic-1.6 neptune-client-0.9.5 rfc3987-1.3.8 simplejson-3.17.2 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 websocket-client-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y_xFFOvEfvY",
        "outputId": "908c6125-a5dc-456a-b935-29617cc89c8a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  2 15:45:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjrPOwLJnRv"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from adamp import AdamP\n",
        "\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "# from fastai.vision.all import *\n",
        "\n",
        "from sklearn.model_selection import GroupKFold, KFold\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts, _LRScheduler\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "import albumentations as A\n",
        "from torch.nn import functional as F\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import timm\n",
        "\n",
        "import neptune\n",
        "# import encoding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiYA7eeXLp05"
      },
      "source": [
        "# run = neptune.init('vvvic313/trash-segmentation', api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlODg2NjVlNC01YjIxLTQ3ZGItYWVkYS05MGFiYWNjMGI2YjUifQ==')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4FWp2qrLmT_"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5x-rujXLmWN"
      },
      "source": [
        "CFG = {\n",
        "    \"img_size\": 512,\n",
        "    \"num_workers\": 4,\n",
        "    \"scheduler\": \"Warmup\",\n",
        "    \"epochs\": 20,\n",
        "    \"criterion\": \"CELoss\",\n",
        "    \"decoder\": \"DeepLabV3Plus\",\n",
        "    \"encoder\": \"resnext50_32x4d\",\n",
        "    \"pretrained\": \"imagenet\",\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 8,\n",
        "    \"weight_decay\": 1e-6,\n",
        "    \"gradient_accumulation_steps\": 4,\n",
        "    \"seed\": 42,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"mean\": (0.485, 0.456, 0.406),\n",
        "    \"std\": (0.229, 0.224, 0.225),\n",
        "    \"mix_prob\": 0.5,\n",
        "    \"pseudo_label\": True\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytCrrgqLmYY"
      },
      "source": [
        "seed_everything(CFG['seed'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT44V4irLma_"
      },
      "source": [
        "def get_train_augmentations():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p = 0.5),\n",
        "        A.VerticalFlip(p = 0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.Cutout(),\n",
        "        A.RandomBrightnessContrast(),\n",
        "        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshBGtjBo1RO"
      },
      "source": [
        "# neptune.create_experiment(name=\"day_0502\", params=CFG)\n",
        "# neptune.append_tag(\"effb3\", \"deeplabv3+\",  \"heavy_aug\", \"fold2\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbXfehKeLmda"
      },
      "source": [
        "def get_validation_augmentations():\n",
        "    return A.Compose([\n",
        "        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ],p=1.0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec-1gT4BL3wX"
      },
      "source": [
        "class TrashDataset(Dataset):\n",
        "    def __init__(self, df, root=\"/content/drive/MyDrive/trash_segmentation/data/\", mode=\"train\", transform=None):\n",
        "        self.df = df.reset_index(drop=True).copy()\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "        self.root = root\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.root + self.df.iloc[idx]['filepath']\n",
        "        imgs = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        \n",
        "        if self.mode==\"train\" or self.mode==\"val\":\n",
        "            mask_path = self.root + self.df.iloc[idx]['masks']\n",
        "            masks = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "            transformed = self.transform(image=imgs, mask=masks)\n",
        "            imgs = transformed[\"image\"]\n",
        "            masks = transformed[\"mask\"]\n",
        "\n",
        "            return imgs, masks\n",
        "        \n",
        "        elif self.mode == \"test\":\n",
        "            transformed = self.transform(image=imgs)\n",
        "            imgs = transformed[\"image\"]\n",
        "            \n",
        "            return imgs, 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_cpkGAVL3y2"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/train.csv\")\n",
        "\n",
        "if CFG['psuedo_label']:\n",
        "    additional_df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/test.csv\")\n",
        "    df = pd.concat([df, additional_df], ignore_index=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVpCSoBFFpq1"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS52zkpML31J"
      },
      "source": [
        "def prepare_dataloader(df, fold):\n",
        "    train_ids = df[~df.Folds.isin(fold)]\n",
        "    val_ids = df[df.Folds.isin(fold)]\n",
        "\n",
        "    train_ds = TrashDataset(train_ids, mode=\"train\", transform=get_train_augmentations())\n",
        "    val_ds = TrashDataset(val_ids, mode=\"val\", transform=get_validation_augmentations())\n",
        "    \n",
        "    train_loader = DataLoader(train_ds, \n",
        "                              batch_size=CFG[\"batch_size\"], \n",
        "                              shuffle=True, \n",
        "                              num_workers=CFG[\"num_workers\"],\n",
        "                              collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_ds,\n",
        "                            batch_size=CFG[\"batch_size\"],\n",
        "                            shuffle=False,\n",
        "                            num_workers=CFG[\"num_workers\"],\n",
        "                            collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, val_loader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcIKkNoOL33e"
      },
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1e-7):\n",
        "        \n",
        "        inputs = inputs.log_softmax(dim=1).exp()\n",
        "        \n",
        "        bs = targets.size(0)\n",
        "        num_classes = inputs.size(1)\n",
        "        dims = (0, 2)\n",
        "        \n",
        "        \n",
        "        targets = targets.view(bs, -1)\n",
        "        inputs = inputs.view(bs, num_classes, -1)\n",
        "        \n",
        "        targets = F.one_hot(targets, num_classes)\n",
        "        targets = targets.permute(0, 2, 1)\n",
        "        \n",
        "        intersection = torch.sum(inputs * targets, dim=dims)\n",
        "        cardinality = torch.sum(inputs + targets, dim=dims)\n",
        "        \n",
        "        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n",
        "        \n",
        "        loss = 1 - dice\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hJapCwQL35v"
      },
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        \n",
        "    def forward(self, inputs, targets, smooth=1e-7):\n",
        "        \n",
        "#         ce_loss = nn.CrossEntropy()(inputs, targets)\n",
        "        ce_loss = F.cross_entropy(inputs, targets)\n",
        "        \n",
        "        inputs = inputs.log_softmax(dim=1).exp()\n",
        "        \n",
        "        bs = targets.size(0)\n",
        "        num_classes = inputs.size(1)\n",
        "        dims = (0, 2)\n",
        "        \n",
        "        targets = targets.view(bs, -1)\n",
        "        inputs = inputs.view(bs, num_classes, -1)\n",
        "        \n",
        "        targets = F.one_hot(targets, num_classes)\n",
        "        targets = targets.permute(0, 2, 1)\n",
        "        \n",
        "        intersection = torch.sum(inputs * targets, dim=dims)\n",
        "        cardinality = torch.sum(inputs + targets, dim=dims)\n",
        "        \n",
        "        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n",
        "        \n",
        "        loss = 1 - dice\n",
        "\n",
        "        mask = targets.sum(dims) > 0\n",
        "        loss *= mask.to(loss.dtype)\n",
        "\n",
        "\n",
        "        return (loss.mean()) +  ce_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3N-Rf9L38E"
      },
      "source": [
        "criterion = None\n",
        "if CFG['criterion'] == \"DiceLoss\":\n",
        "    criterion = DiceLoss()\n",
        "elif CFG['criterion'] == \"CELoss\":\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "elif CFG['criterion'] == \"CustomLoss\":\n",
        "    criterion = CustomLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCzJGRmkL3-p"
      },
      "source": [
        "class CustomCosineAnnealingWarmUpRestarts(_LRScheduler):\n",
        "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
        "        if T_0 <= 0 or not isinstance(T_0, int):\n",
        "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
        "        if T_mult < 1 or not isinstance(T_mult, int):\n",
        "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
        "        if T_up < 0 or not isinstance(T_up, int):\n",
        "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
        "        self.T_0 = T_0\n",
        "        self.T_mult = T_mult\n",
        "        self.base_eta_max = eta_max\n",
        "        self.eta_max = eta_max\n",
        "        self.T_up = T_up\n",
        "        self.T_i = T_0\n",
        "        self.gamma = gamma\n",
        "        self.cycle = 0\n",
        "        self.T_cur = last_epoch\n",
        "        super(CustomCosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.T_cur == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.T_cur < self.T_up:\n",
        "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.T_cur = self.T_cur + 1\n",
        "            if self.T_cur >= self.T_i:\n",
        "                self.cycle += 1\n",
        "                self.T_cur = self.T_cur - self.T_i\n",
        "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
        "        else:\n",
        "            if epoch >= self.T_0:\n",
        "                if self.T_mult == 1:\n",
        "                    self.T_cur = epoch % self.T_0\n",
        "                    self.cycle = epoch // self.T_0\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
        "                    self.cycle = n\n",
        "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
        "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
        "            else:\n",
        "                self.T_i = self.T_0\n",
        "                self.T_cur = epoch\n",
        "                \n",
        "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ddlE6fwMMSB"
      },
      "source": [
        "def _fast_hist(label_true, label_pred, n_class):\n",
        "    mask = (label_true >= 0) & (label_true < n_class)\n",
        "    hist = np.bincount(\n",
        "        n_class * label_true[mask].astype(int) +\n",
        "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
        "    return hist\n",
        "\n",
        "\n",
        "def label_accuracy_score_(label_trues, label_preds, n_class):\n",
        "    \"\"\"Returns accuracy score evaluation result.\n",
        "      - overall accuracy\n",
        "      - mean accuracy\n",
        "      - mean IU\n",
        "      - fwavacc\n",
        "    \"\"\"\n",
        "    hist = np.zeros((n_class, n_class))\n",
        "    for lt, lp in zip(label_trues, label_preds):\n",
        "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
        "    acc = np.diag(hist).sum() / hist.sum()\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
        "    acc_cls = np.nanmean(acc_cls)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        iu = np.diag(hist) / (\n",
        "            hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n",
        "        )\n",
        "    mean_iu = np.nanmean(iu)\n",
        "    freq = hist.sum(axis=1) / hist.sum()\n",
        "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "    return acc, acc_cls, mean_iu, fwavacc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n8Iee6WMMUR"
      },
      "source": [
        "def label_accuracy_score(hist):\n",
        "    \"\"\"\n",
        "    Returns accuracy score evaluation result.\n",
        "      - [acc]: overall accuracy\n",
        "      - [acc_cls]: mean accuracy\n",
        "      - [mean_iu]: mean IU\n",
        "      - [fwavacc]: fwavacc\n",
        "    \"\"\"\n",
        "    acc = np.diag(hist).sum() / hist.sum()\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
        "    acc_cls = np.nanmean(acc_cls)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
        "    mean_iu = np.nanmean(iu)\n",
        "\n",
        "    freq = hist.sum(axis=1) / hist.sum()\n",
        "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "    return acc, acc_cls, mean_iu, fwavacc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgU8J0coMMWX"
      },
      "source": [
        "def add_hist(hist, label_trues, label_preds, n_class):\n",
        "    \"\"\"\n",
        "        stack hist(confusion matrix)\n",
        "    \"\"\"\n",
        "\n",
        "    for lt, lp in zip(label_trues, label_preds):\n",
        "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
        "\n",
        "    return hist"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTFVol0RRnv"
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1.0 - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFMtLMfxPMIV"
      },
      "source": [
        "def cutmix(data, target, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_target = target[indices]\n",
        "\n",
        "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    new_data = data.clone()\n",
        "    new_target = target.clone()\n",
        "    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n",
        "    new_target[:, bby1:bby2, bbx1:bbx2] = target[indices, bby1:bby2, bbx1:bbx2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "    \n",
        "\n",
        "    return new_data, new_target"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxlrGoiVMMY4"
      },
      "source": [
        "def train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler):\n",
        "    model.train()\n",
        "    running_loss = None\n",
        "    \n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n",
        "\n",
        "    for step, (imgs, masks) in pbar:\n",
        "\n",
        "        if (step+1) == (len(train_loader)):\n",
        "            continue\n",
        "        mix_decision = np.random.rand()\n",
        "        imgs = torch.stack(imgs)\n",
        "        masks = torch.stack(masks)\n",
        "        imgs = imgs.to(device).float()\n",
        "        masks = masks.to(device).long()\n",
        "        \n",
        "        if mix_decision < CFG['mix_prob']:\n",
        "            imgs, masks = cutmix(imgs, masks, 1.0)\n",
        "\n",
        "        with autocast():\n",
        "            model.to(device)\n",
        "            mask_preds = model(imgs)\n",
        "            loss = criterion(mask_preds, masks) / CFG['gradient_accumulation_steps']\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # loss.backward()\n",
        "\n",
        "            if running_loss is None:\n",
        "                running_loss = loss.item() * CFG['gradient_accumulation_steps']\n",
        "            else:\n",
        "                running_loss = running_loss * 0.99 + loss.item() * CFG['gradient_accumulation_steps'] * 0.01\n",
        "\n",
        "            if ((step + 1) % CFG[\"gradient_accumulation_steps\"]==0) or ((step+1) == (len(train_loader))):\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                # optimizer.zero_grad()\n",
        "                # optimizer.step()                            \n",
        "                optimizer.zero_grad() \n",
        "                description = f\"epoch {epoch} loss: {running_loss: .4f}\"\n",
        "                pbar.set_description(description)\n",
        "                \n",
        "    scheduler.step()        "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWRZ04KxMMbX"
      },
      "source": [
        "def valid_one_epoch(epoch, model, device, criterion, val_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    running_loss = None\n",
        "    cnt = 0\n",
        "    mIoU_list = []\n",
        "    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0, leave=True)\n",
        "    hist = np.zeros((12, 12))\n",
        "    for step, (imgs, masks) in pbar:\n",
        "        if (step+1) == (len(train_loader)):\n",
        "            continue\n",
        "        imgs = torch.stack(imgs)\n",
        "        masks = torch.stack(masks)\n",
        "        imgs = imgs.to(device).float()\n",
        "        masks = masks.to(device).long()\n",
        "        \n",
        "        cnt += 1\n",
        "\n",
        "        mask_preds = model(imgs)\n",
        "        # print(f\"{mask_preds.shape}       \")\n",
        "        loss = criterion(mask_preds, masks)\n",
        "\n",
        "        mask_preds = torch.argmax(mask_preds, dim=1).detach().cpu().numpy()\n",
        "        # print(mask_preds.shape)\n",
        "\n",
        "        mIoU = label_accuracy_score_(masks.detach().cpu().numpy(), mask_preds, n_class=12)[2]\n",
        "        mIoU_list.append(mIoU)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "            \n",
        "        if running_loss is None:\n",
        "            running_loss = loss.item()\n",
        "        else:\n",
        "            running_loss = running_loss * 0.99 + loss.item() * 0.01\n",
        "\n",
        "        description = f'epoch {epoch} Loss: {running_loss:.4f}, mIoU: {np.mean(mIoU_list):.4f}'\n",
        "        pbar.set_description(description)\n",
        "\n",
        "    return total_loss/cnt, np.mean(mIoU_list)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf1S2tfnMMdw"
      },
      "source": [
        "FOLDS = 5\n",
        "kf = KFold(FOLDS, shuffle=True, random_state=CFG['seed'])\n",
        "df[\"Folds\"] = 0\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
        "    df.loc[val_idx, 'Folds'] = fold"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgls-tqKMS0V"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERQDJsYZMS2o"
      },
      "source": [
        "def create_folder(directory):\n",
        "    try:\n",
        "        os.makedirs(directory)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "543ad93940fe4818aba0b61fd76a18e6",
            "85b0960742da4c73982950e8b30afd78",
            "868c3e5eb2d34112b31b0f1d4551504c",
            "60fcd8187ac4446bad51c0dacd1afb26",
            "2a45ba369f0e4f1190798d79a4762420",
            "f61bbd87adba4532bbfb33ce907e5520",
            "a470d78f21954d4e8f3dd99c4aadd52c",
            "eebf27e1ad0b49dcb7a98ebb67bbf800"
          ]
        },
        "id": "KMzx6Tb8MS43",
        "outputId": "61e95043-cc9a-4654-95f2-01ac9bffdba6"
      },
      "source": [
        "for fold in range(FOLDS):\n",
        "    # if fold != 0:\n",
        "    #   continue\n",
        "    print(f\"{fold} fold start\")\n",
        "    \n",
        "    if CFG['decoder'] == \"Unetpp\":\n",
        "        model = smp.UnetPlusPlus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == 'DeepLabV3Plus':\n",
        "        model = smp.DeepLabV3Plus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == 'DeepLabV3':\n",
        "        model = smp.DeepLabV3(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == \"UperNet\":\n",
        "        model = encoding.models.sseg.UperNet(12, CFG['encoder'], aux=False)\n",
        "    \n",
        "    if CFG['scheduler'] == \"Warmup\":\n",
        "        if CFG['optimizer'] == \"Adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0, weight_decay=CFG['weight_decay'])\n",
        "            scheduler = CustomCosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_max=CFG['lr'], T_up=CFG['epochs']//10, gamma=1.)\n",
        "    else:\n",
        "        if CFG['optimizer'] == \"Adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
        "    \n",
        "    scaler = GradScaler()\n",
        "    train_loader, valid_loader = prepare_dataloader(df, [fold])\n",
        "    \n",
        "    best_mIoU = 0\n",
        "    num_epochs = CFG['epochs']\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            epoch_loss, mIoU = valid_one_epoch(epoch, model, device, criterion, valid_loader)\n",
        "\n",
        "        # neptune.log_metric(f\"fold{fold} epoch loss\", epoch_loss)\n",
        "        # neptune.log_metric(f\"fold{fold} mIoU\", mIoU)\n",
        "\n",
        "        if best_mIoU < mIoU:\n",
        "            best_mIoU = mIoU\n",
        "            dir_ = f\"/content/drive/MyDrive/trash_segmentation/models\"\n",
        "            create_folder(dir_)\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'scheduler': scheduler.state_dict()\n",
        "                        }, f\"{dir_}/{CFG['encoder']}_{fold}.pth\")\n",
        "            print(\"model is saved\")\n",
        "        print(\"\")\n",
        "\n",
        "    # neptune.log_metric(f\"fold {fold} Best mIoU\", best_mIoU)\n",
        "    del model, optimizer, train_loader, valid_loader, scheduler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "# neptune.stop()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 fold start\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext101_32x4d-3b2fe3d8.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "543ad93940fe4818aba0b61fd76a18e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=196466866.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 loss:  2.5130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 0 Loss: 2.5256, mIoU: 0.0101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 loss:  1.2955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:25<00:00,  1.54s/it]\n",
            "epoch 1 Loss: 0.9083, mIoU: 0.2437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 loss:  0.7380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 2 Loss: 0.5573, mIoU: 0.3502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 loss:  0.5439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 3 Loss: 0.4575, mIoU: 0.3867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 loss:  0.4383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 4 Loss: 0.3703, mIoU: 0.4215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 loss:  0.3869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 5 Loss: 0.3413, mIoU: 0.4302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 loss:  0.3373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 6 Loss: 0.3447, mIoU: 0.4309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 loss:  0.2946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:23<00:00,  1.53s/it]\n",
            "epoch 7 Loss: 0.3780, mIoU: 0.4472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 loss:  0.2684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 8 Loss: 0.3386, mIoU: 0.4511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 loss:  0.2486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 9 Loss: 0.3442, mIoU: 0.4581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 loss:  0.2345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:25<00:00,  1.54s/it]\n",
            "epoch 10 Loss: 0.3719, mIoU: 0.4453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11 loss:  0.2050: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:23<00:00,  1.53s/it]\n",
            "epoch 11 Loss: 0.3569, mIoU: 0.4694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 loss:  0.1977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:23<00:00,  1.54s/it]\n",
            "epoch 12 Loss: 0.3181, mIoU: 0.4629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13 loss:  0.1871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 13 Loss: 0.2986, mIoU: 0.4734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 loss:  0.1598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 14 Loss: 0.3092, mIoU: 0.4728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15 loss:  0.1691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 15 Loss: 0.3210, mIoU: 0.4646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:37<00:00,  1.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16 loss:  0.1626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:19<00:00,  1.52s/it]\n",
            "epoch 16 Loss: 0.3097, mIoU: 0.4679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:36<00:00,  1.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17 loss:  0.1607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:20<00:00,  1.53s/it]\n",
            "epoch 17 Loss: 0.3079, mIoU: 0.4654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:37<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18 loss:  0.1577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:17<00:00,  1.52s/it]\n",
            "epoch 18 Loss: 0.2993, mIoU: 0.4668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:37<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19 loss:  0.1591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 328/328 [08:17<00:00,  1.52s/it]\n",
            "epoch 19 Loss: 0.3033, mIoU: 0.4736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [01:36<00:00,  1.18s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGV2VIve5JvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}