{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trash_seg_train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1hA-fGXo59EnvFZLC15gjMt4m9pOOWPRP","authorship_tag":"ABX9TyOemuq/POBLRgF2fTDisxz3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZx9ELQBJT-E","executionInfo":{"status":"ok","timestamp":1620188794921,"user_tz":-540,"elapsed":35610,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}},"outputId":"33aba97d-7ee7-4e47-a0c5-2f697dd94c0c"},"source":["!pip install segmentation_models_pytorch\n","!pip install -q -U albumentations\n","!pip install timm\n","!pip install adamp\n","!pip install neptune-client\n","!pip install fastai --upgrade"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting segmentation_models_pytorch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n","\r\u001b[K     |█████                           | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 27.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.9.1+cu101)\n","Collecting pretrainedmodels==0.7.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n","\u001b[?25hCollecting timm==0.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n","\u001b[K     |████████████████████████████████| 245kB 19.8MB/s \n","\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n","  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n","Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.8.1+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.19.5)\n","Collecting munch\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision>=0.3.0->segmentation_models_pytorch) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n","Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=36b72d9a292e8f969caeefee1e11416ee2d688cf7fa2c0fb81b978bf9b2af9bf\n","  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=1fbf19a89affa14de03899a358ebc99536fe64d8e6a398a8764d533a28c476fc\n","  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n","Successfully built pretrainedmodels efficientnet-pytorch\n","Installing collected packages: munch, pretrainedmodels, timm, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n","\u001b[K     |████████████████████████████████| 81kB 7.6MB/s \n","\u001b[K     |████████████████████████████████| 37.6MB 126kB/s \n","\u001b[K     |████████████████████████████████| 952kB 59.1MB/s \n","\u001b[?25hRequirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.3.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm) (3.7.4.3)\n","Collecting adamp\n","  Downloading https://files.pythonhosted.org/packages/c8/56/182b8c93f18feb0244b83f9b2eff1c6b036c04d4c3880e8d222750b0d5e5/adamp-0.3.0.tar.gz\n","Building wheels for collected packages: adamp\n","  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adamp: filename=adamp-0.3.0-cp37-none-any.whl size=5999 sha256=a9002334e55963a53c5ed96ef05ade1099c2b92d02db9a1ec2697cbd5b246123\n","  Stored in directory: /root/.cache/pip/wheels/6a/89/67/879fe55977ebcbfaa5b929eb111af7fe11eb3552867850dd76\n","Successfully built adamp\n","Installing collected packages: adamp\n","Successfully installed adamp-0.3.0\n","Collecting neptune-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/b8/73eb6c462ffe3d833e4ef93283ab8bf61f665862048d85a9eac24bfe9532/neptune-client-0.9.7.tar.gz (216kB)\n","\u001b[K     |████████████████████████████████| 225kB 12.4MB/s \n","\u001b[?25hCollecting bravado\n","  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting future>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 19.3MB/s \n","\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n","Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n","Collecting PyJWT\n","  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n","Collecting websocket-client>=0.35.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/0c/d52a2a63512a613817846d430d16a8fbe5ea56dd889e89c68facf6b91cb6/websocket_client-0.59.0-py2.py3-none-any.whl (67kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n","\u001b[?25hCollecting GitPython>=2.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 23.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (20.9)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n","Collecting bravado-core>=5.16.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.7.4.3)\n","Collecting simplejson\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 33.5MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (2.8.1)\n","Collecting monotonic\n","  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n","Collecting jsonref\n","  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n","Collecting swagger-spec-validator>=2.0.1\n","  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n","Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Collecting strict-rfc3339; extra == \"format\"\n","  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n","Collecting rfc3987; extra == \"format\"\n","  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n","Collecting webcolors; extra == \"format\"\n","  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n","Building wheels for collected packages: neptune-client, future, strict-rfc3339\n","  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for neptune-client: filename=neptune_client-0.9.7-py2.py3-none-any.whl size=389578 sha256=3d2278727f9133e8b7b41829d643da20aabc9d60bdcee1c85e82fe3599e5515e\n","  Stored in directory: /root/.cache/pip/wheels/bd/17/9e/9160edeebe214e70b7cbe39374f989e52290f635f2262785a6\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=53d775c261cffe5d74aa3907025386376e662d176b8098efe9d0ccd73f086174\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp37-none-any.whl size=18121 sha256=a8affbbb2d38c73c65af4e4bb7b9586c7024160a2ab4d4d4161d6a0932a1324b\n","  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n","Successfully built neptune-client future strict-rfc3339\n","Installing collected packages: simplejson, jsonref, swagger-spec-validator, bravado-core, monotonic, bravado, future, PyJWT, websocket-client, smmap, gitdb, GitPython, neptune-client, strict-rfc3339, rfc3987, webcolors\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed GitPython-3.1.14 PyJWT-2.1.0 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jsonref-0.2 monotonic-1.6 neptune-client-0.9.7 rfc3987-1.3.8 simplejson-3.17.2 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 websocket-client-0.59.0\n","Collecting fastai\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/79/e8a87e4c20238e114671314426227db8647d2b42744eab79e0917c59865e/fastai-2.3.1-py3-none-any.whl (194kB)\n","\u001b[K     |████████████████████████████████| 204kB 12.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n","Collecting fastcore<1.4,>=1.3.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n","Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n","Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n","Requirement already satisfied, skipping upgrade: torch<1.9,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n","Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n","Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.9.1+cu101)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n","Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n","Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (56.0.0)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n","Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n","Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n","Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9,>=1.7.0->fastai) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai) (1.15.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n","Installing collected packages: fastcore, fastai\n","  Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","Successfully installed fastai-2.3.1 fastcore-1.3.20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Y_xFFOvEfvY","executionInfo":{"status":"ok","timestamp":1620190314003,"user_tz":-540,"elapsed":726,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}},"outputId":"698db7bd-531f-46e5-a299-05189224d5e2"},"source":["!nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Wed May  5 04:51:55 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    24W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3vjrPOwLJnRv","executionInfo":{"status":"ok","timestamp":1620201792837,"user_tz":-540,"elapsed":2949,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["import segmentation_models_pytorch as smp\n","from tqdm import tqdm\n","import gc\n","from adamp import AdamP\n","from typing import Optional\n","\n","import math\n","from torch.optim.optimizer import Optimizer, required\n","\n","from fastai.vision.all import *\n","\n","from sklearn.model_selection import GroupKFold, KFold\n","import torch\n","from torch import nn\n","import torchvision\n","import cv2\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","from torchvision import transforms\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.data.sampler import SequentialSampler, RandomSampler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts, _LRScheduler\n","from scipy.ndimage.interpolation import zoom\n","import albumentations as A\n","from torch.nn import functional as F\n","from albumentations.pytorch import ToTensorV2\n","\n","from pycocotools.coco import COCO\n","\n","import matplotlib.pyplot as plt\n","import sys\n","import time\n","import random\n","import timm\n","\n","import neptune\n","# import encoding"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"q36KoXw6g4n-","executionInfo":{"status":"ok","timestamp":1620201828373,"user_tz":-540,"elapsed":38478,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["# sys.path.append('/content/drive/MyDrive/trash_segmentation/data/segmentation_models.pytorch-master')\n","\n","# import segmentation_models_pytorch as smp"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"wiYA7eeXLp05","executionInfo":{"status":"ok","timestamp":1620201828376,"user_tz":-540,"elapsed":38477,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["# run = neptune.init('vvvic313/trash-segmentation', api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlODg2NjVlNC01YjIxLTQ3ZGItYWVkYS05MGFiYWNjMGI2YjUifQ==')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4FWp2qrLmT_","executionInfo":{"status":"ok","timestamp":1620201828377,"user_tz":-540,"elapsed":38472,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5x-rujXLmWN","executionInfo":{"status":"ok","timestamp":1620201828377,"user_tz":-540,"elapsed":38468,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["CFG = {\n","    \"img_size\": 512,\n","    \"num_workers\": 4,\n","    \"scheduler\": \"Warmup\",\n","    \"epochs\": 25,\n","    \"criterion\": \"SoftCELoss\",\n","    \"decoder\": \"UneXt\",\n","    \"encoder\": \"resnext50\",\n","    \"pretrained\": \"swsl\",\n","    \"lr\": 1e-4,\n","    \"batch_size\": 8,\n","    \"weight_decay\": 1e-6,\n","    \"gradient_accumulation_steps\": 4,\n","    \"seed\": 42,\n","    \"optimizer\": \"AdamW\",\n","    \"mean\": (0.485, 0.456, 0.406),\n","    \"std\": (0.229, 0.224, 0.225),\n","    \"mix_prob\": 0,\n","    \"pseudo_label\": True\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"fytCrrgqLmYY","executionInfo":{"status":"ok","timestamp":1620201828377,"user_tz":-540,"elapsed":38463,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["seed_everything(CFG['seed'])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"KT44V4irLma_","executionInfo":{"status":"ok","timestamp":1620201828378,"user_tz":-540,"elapsed":38458,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def get_train_augmentations():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.ShiftScaleRotate(p=0.5),\n","        A.Cutout(),\n","        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n","        ToTensorV2()\n","    ], p=1.0)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"BshBGtjBo1RO","executionInfo":{"status":"ok","timestamp":1620201828378,"user_tz":-540,"elapsed":38453,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["# neptune.create_experiment(name=\"day_0502\", params=CFG)\n","# neptune.append_tag(\"effb3\", \"deeplabv3+\",  \"heavy_aug\", \"fold2\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbXfehKeLmda","executionInfo":{"status":"ok","timestamp":1620201828378,"user_tz":-540,"elapsed":38449,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def get_validation_augmentations():\n","    return A.Compose([\n","        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n","        ToTensorV2()\n","    ],p=1.0)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec-1gT4BL3wX","executionInfo":{"status":"ok","timestamp":1620201828378,"user_tz":-540,"elapsed":38444,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class TrashDataset(Dataset):\n","    def __init__(self, df, root=\"/content/drive/MyDrive/trash_segmentation/data/\", mode=\"train\", transform=None):\n","        self.df = df.reset_index(drop=True).copy()\n","        self.mode = mode\n","        self.transform = transform\n","        self.root = root\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        image_path = self.root + self.df.iloc[idx]['filepath']\n","        imgs = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n","        \n","        \n","        if self.mode==\"train\" or self.mode==\"val\":\n","            mask_path = self.root + self.df.iloc[idx]['masks']\n","            masks = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n","            transformed = self.transform(image=imgs, mask=masks)\n","            imgs = transformed[\"image\"]\n","            masks = transformed[\"mask\"]\n","\n","            return imgs, masks\n","        \n","        elif self.mode == \"test\":\n","            transformed = self.transform(image=imgs)\n","            imgs = transformed[\"image\"]\n","            \n","            return imgs, 1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_cpkGAVL3y2","executionInfo":{"status":"ok","timestamp":1620201828379,"user_tz":-540,"elapsed":38441,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/train.csv\")\n","\n","if CFG['pseudo_label']:\n","    additional_df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/test.csv\")\n","    df = pd.concat([df, additional_df], ignore_index=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVpCSoBFFpq1","executionInfo":{"status":"ok","timestamp":1620201828379,"user_tz":-540,"elapsed":38435,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"wS52zkpML31J","executionInfo":{"status":"ok","timestamp":1620201828379,"user_tz":-540,"elapsed":38430,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def prepare_dataloader(df, fold):\n","    train_ids = df[~df.Folds.isin(fold)]\n","    val_ids = df[df.Folds.isin(fold)]\n","\n","    train_ds = TrashDataset(train_ids, mode=\"train\", transform=get_train_augmentations())\n","    val_ds = TrashDataset(val_ids, mode=\"val\", transform=get_validation_augmentations())\n","    \n","    train_loader = DataLoader(train_ds, \n","                              batch_size=CFG[\"batch_size\"], \n","                              shuffle=True, \n","                              num_workers=CFG[\"num_workers\"],\n","                              collate_fn=collate_fn)\n","    val_loader = DataLoader(val_ds,\n","                            batch_size=CFG[\"batch_size\"],\n","                            shuffle=False,\n","                            num_workers=CFG[\"num_workers\"],\n","                            collate_fn=collate_fn)\n","    \n","    return train_loader, val_loader"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwhoctivKalL","executionInfo":{"status":"ok","timestamp":1620201829270,"user_tz":-540,"elapsed":39316,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class FPN(nn.Module):\n","    def __init__(self, input_channels:list, output_channels:list):\n","        super().__init__()\n","        self.convs = nn.ModuleList(\n","            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n","             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n","             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n","            for in_ch, out_ch in zip(input_channels, output_channels)])\n","        \n","    def forward(self, xs:list, last_layer):\n","        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear') \n","               for i,(c,x) in enumerate(zip(self.convs, xs))]\n","        hcs.append(last_layer)\n","        return torch.cat(hcs, dim=1)\n","\n","class UnetBlock(Module):\n","    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n","                 self_attention:bool=False, **kwargs):\n","        super().__init__()\n","        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n","        self.bn = nn.BatchNorm2d(x_in_c)\n","        ni = up_in_c//2 + x_in_c\n","        nf = nf if nf is not None else max(up_in_c//2,32)\n","        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n","        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n","            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n","        s = left_in\n","        up_out = self.shuf(up_in)\n","        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n","        return self.conv2(self.conv1(cat_x))\n","        \n","class _ASPPModule(nn.Module):\n","    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n","        super().__init__()\n","        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n","                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n","        self.bn = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU()\n","\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x = self.atrous_conv(x)\n","        x = self.bn(x)\n","\n","        return self.relu(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class ASPP(nn.Module):\n","    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n","        super().__init__()\n","        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n","            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n","        self.aspps = nn.ModuleList(self.aspps)\n","        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n","                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n","                        nn.BatchNorm2d(mid_c), nn.ReLU())\n","        out_c = out_c if out_c is not None else mid_c\n","        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n","                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n","        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x0 = self.global_pool(x)\n","        xs = [aspp(x) for aspp in self.aspps]\n","        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n","        x = torch.cat([x0] + xs, dim=1)\n","        return self.out_conv(x)\n","    \n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1KP4cfoLa_x"},"source":["## UneXt50"]},{"cell_type":"code","metadata":{"id":"S9NDuIfYKdF5","executionInfo":{"status":"ok","timestamp":1620201829271,"user_tz":-540,"elapsed":39312,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class UneXt50(nn.Module):\n","    def __init__(self, stride=1, **kwargs):\n","        super().__init__()\n","        #encoder\n","        # m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n","        #                    'resnext50_32x4d_ssl')\n","        m = timm.create_model(\"swsl_resnext50_32x4d\", pretrained=True)\n","        self.enc0 = nn.Sequential(m.conv1, m.bn1, nn.ReLU(inplace=True))\n","        self.enc1 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1),\n","                            m.layer1) #256\n","        self.enc2 = m.layer2 #512\n","        self.enc3 = m.layer3 #1024\n","        self.enc4 = m.layer4 #2048\n","        #aspp with customized dilatations\n","        self.aspp = ASPP(2048,256,out_c=512,dilations=[stride*1,stride*2,stride*3,stride*4])\n","        self.drop_aspp = nn.Dropout2d(0.5)\n","        #decoder\n","        self.dec4 = UnetBlock(512,1024,256)\n","        self.dec3 = UnetBlock(256,512,128)\n","        self.dec2 = UnetBlock(128,256,64)\n","        self.dec1 = UnetBlock(64,64,32)\n","        self.fpn = FPN([512,256,128,64],[16]*4)\n","        self.drop = nn.Dropout2d(0.1)\n","        self.final_conv = ConvLayer(32+16*4, 12, ks=1, norm_type=None, act_cls=None)\n","        \n","    def forward(self, x):\n","        enc0 = self.enc0(x)\n","        enc1 = self.enc1(enc0)\n","        enc2 = self.enc2(enc1)\n","        enc3 = self.enc3(enc2)\n","        enc4 = self.enc4(enc3)\n","        enc5 = self.aspp(enc4)\n","        dec3 = self.dec4(self.drop_aspp(enc5),enc3)\n","        dec2 = self.dec3(dec3,enc2)\n","        dec1 = self.dec2(dec2,enc1)\n","        dec0 = self.dec1(dec1,enc0)\n","        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n","        x = self.final_conv(self.drop(x))\n","        x = F.interpolate(x,scale_factor=2,mode='bilinear')\n","        return x"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcIKkNoOL33e","executionInfo":{"status":"ok","timestamp":1620201829271,"user_tz":-540,"elapsed":39307,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class DiceLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1e-7):\n","        \n","        inputs = inputs.log_softmax(dim=1).exp()\n","        \n","        bs = targets.size(0)\n","        num_classes = inputs.size(1)\n","        dims = (0, 2)\n","        \n","        \n","        targets = targets.view(bs, -1)\n","        inputs = inputs.view(bs, num_classes, -1)\n","        \n","        targets = F.one_hot(targets, num_classes)\n","        targets = targets.permute(0, 2, 1)\n","        \n","        intersection = torch.sum(inputs * targets, dim=dims)\n","        cardinality = torch.sum(inputs + targets, dim=dims)\n","        \n","        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n","        \n","        loss = 1 - dice\n","        \n","        return loss"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hJapCwQL35v","executionInfo":{"status":"ok","timestamp":1620201829271,"user_tz":-540,"elapsed":39303,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class CustomLoss(nn.Module):\n","    def __init__(self):\n","        super(CustomLoss, self).__init__()\n","        \n","    def forward(self, inputs, targets, smooth=1e-7):\n","        \n","#         ce_loss = nn.CrossEntropy()(inputs, targets)\n","        ce_loss = F.cross_entropy(inputs, targets)\n","        \n","        inputs = inputs.log_softmax(dim=1).exp()\n","        \n","        bs = targets.size(0)\n","        num_classes = inputs.size(1)\n","        dims = (0, 2)\n","        \n","        targets = targets.view(bs, -1)\n","        inputs = inputs.view(bs, num_classes, -1)\n","        \n","        targets = F.one_hot(targets, num_classes)\n","        targets = targets.permute(0, 2, 1)\n","        \n","        intersection = torch.sum(inputs * targets, dim=dims)\n","        cardinality = torch.sum(inputs + targets, dim=dims)\n","        \n","        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n","        \n","        loss = 1 - dice\n","\n","        mask = targets.sum(dims) > 0\n","        loss *= mask.to(loss.dtype)\n","\n","\n","        return (loss.mean()) +  ce_loss"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"60XOAoPtiYfH","executionInfo":{"status":"ok","timestamp":1620201829272,"user_tz":-540,"elapsed":39298,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def label_smoothed_nll_loss(\n","    lprobs: torch.Tensor, target: torch.Tensor, epsilon: float, ignore_index=None, reduction=\"mean\", dim=-1\n",") -> torch.Tensor:\n","    \"\"\"\n","    Source: https://github.com/pytorch/fairseq/blob/master/fairseq/criterions/label_smoothed_cross_entropy.py\n","    :param lprobs: Log-probabilities of predictions (e.g after log_softmax)\n","    :param target:\n","    :param epsilon:\n","    :param ignore_index:\n","    :param reduction:\n","    :return:\n","    \"\"\"\n","    if target.dim() == lprobs.dim() - 1:\n","        target = target.unsqueeze(dim)\n","\n","    if ignore_index is not None:\n","        pad_mask = target.eq(ignore_index)\n","        target = target.masked_fill(pad_mask, 0)\n","        nll_loss = -lprobs.gather(dim=dim, index=target)\n","        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n","\n","        # nll_loss.masked_fill_(pad_mask, 0.0)\n","        # smooth_loss.masked_fill_(pad_mask, 0.0)\n","        nll_loss = nll_loss.masked_fill(pad_mask, 0.0)\n","        smooth_loss = smooth_loss.masked_fill(pad_mask, 0.0)\n","    else:\n","        nll_loss = -lprobs.gather(dim=dim, index=target)\n","        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n","\n","        nll_loss = nll_loss.squeeze(dim)\n","        smooth_loss = smooth_loss.squeeze(dim)\n","\n","    if reduction == \"sum\":\n","        nll_loss = nll_loss.sum()\n","        smooth_loss = smooth_loss.sum()\n","    if reduction == \"mean\":\n","        nll_loss = nll_loss.mean()\n","        smooth_loss = smooth_loss.mean()\n","\n","    eps_i = epsilon / lprobs.size(dim)\n","    loss = (1.0 - epsilon) * nll_loss + eps_i * smooth_loss\n","    return loss\n","\n","class SoftCrossEntropyLoss(nn.Module):\n","\n","    __constants__ = [\"reduction\", \"ignore_index\", \"smooth_factor\"]\n","\n","    def __init__(\n","        self,\n","        reduction: str = \"mean\",\n","        smooth_factor: Optional[float] = None,\n","        ignore_index: Optional[int] = -100,\n","        dim: int = 1,\n","    ):\n","        \"\"\"Drop-in replacement for torch.nn.CrossEntropyLoss with label_smoothing\n","        \n","        Args:\n","            smooth_factor: Factor to smooth target (e.g. if smooth_factor=0.1 then [1, 0, 0] -> [0.9, 0.05, 0.05])\n","        \n","        Shape\n","             - **y_pred** - torch.Tensor of shape (N, C, H, W)\n","             - **y_true** - torch.Tensor of shape (N, H, W)\n","        Reference\n","            https://github.com/BloodAxe/pytorch-toolbelt\n","        \"\"\"\n","        super().__init__()\n","        self.smooth_factor = smooth_factor\n","        self.ignore_index = ignore_index\n","        self.reduction = reduction\n","        self.dim = dim\n","\n","    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n","        log_prob = F.log_softmax(y_pred, dim=self.dim)\n","        return label_smoothed_nll_loss(\n","            log_prob,\n","            y_true,\n","            epsilon=self.smooth_factor,\n","            ignore_index=self.ignore_index,\n","            reduction=self.reduction,\n","            dim=self.dim,\n","        )"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"YE3N-Rf9L38E","executionInfo":{"status":"ok","timestamp":1620201829272,"user_tz":-540,"elapsed":39294,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["criterion = None\n","if CFG['criterion'] == \"DiceLoss\":\n","    criterion = DiceLoss()\n","elif CFG['criterion'] == \"CELoss\":\n","    criterion = nn.CrossEntropyLoss()\n","elif CFG['criterion'] == \"CustomLoss\":\n","    criterion = CustomLoss()\n","elif CFG['criterion'] == \"SoftCELoss\":\n","    criterion = SoftCrossEntropyLoss(smooth_factor=0.1)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCzJGRmkL3-p","executionInfo":{"status":"ok","timestamp":1620201829272,"user_tz":-540,"elapsed":39289,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["class CustomCosineAnnealingWarmUpRestarts(_LRScheduler):\n","    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n","        if T_0 <= 0 or not isinstance(T_0, int):\n","            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n","        if T_mult < 1 or not isinstance(T_mult, int):\n","            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n","        if T_up < 0 or not isinstance(T_up, int):\n","            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n","        self.T_0 = T_0\n","        self.T_mult = T_mult\n","        self.base_eta_max = eta_max\n","        self.eta_max = eta_max\n","        self.T_up = T_up\n","        self.T_i = T_0\n","        self.gamma = gamma\n","        self.cycle = 0\n","        self.T_cur = last_epoch\n","        super(CustomCosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n","        \n","    \n","    def get_lr(self):\n","        if self.T_cur == -1:\n","            return self.base_lrs\n","        elif self.T_cur < self.T_up:\n","            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n","                    for base_lr in self.base_lrs]\n","\n","    def step(self, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","            self.T_cur = self.T_cur + 1\n","            if self.T_cur >= self.T_i:\n","                self.cycle += 1\n","                self.T_cur = self.T_cur - self.T_i\n","                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n","        else:\n","            if epoch >= self.T_0:\n","                if self.T_mult == 1:\n","                    self.T_cur = epoch % self.T_0\n","                    self.cycle = epoch // self.T_0\n","                else:\n","                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n","                    self.cycle = n\n","                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n","                    self.T_i = self.T_0 * self.T_mult ** (n)\n","            else:\n","                self.T_i = self.T_0\n","                self.T_cur = epoch\n","                \n","        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n","        self.last_epoch = math.floor(epoch)\n","        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n","            param_group['lr'] = lr"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ddlE6fwMMSB","executionInfo":{"status":"ok","timestamp":1620201829273,"user_tz":-540,"elapsed":39285,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def _fast_hist(label_true, label_pred, n_class):\n","    mask = (label_true >= 0) & (label_true < n_class)\n","    hist = np.bincount(\n","        n_class * label_true[mask].astype(int) +\n","        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n","    return hist\n","\n","\n","def label_accuracy_score_(label_trues, label_preds, n_class):\n","    \"\"\"Returns accuracy score evaluation result.\n","      - overall accuracy\n","      - mean accuracy\n","      - mean IU\n","      - fwavacc\n","    \"\"\"\n","    hist = np.zeros((n_class, n_class))\n","    for lt, lp in zip(label_trues, label_preds):\n","        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n","    acc = np.diag(hist).sum() / hist.sum()\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        acc_cls = np.diag(hist) / hist.sum(axis=1)\n","    acc_cls = np.nanmean(acc_cls)\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        iu = np.diag(hist) / (\n","            hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n","        )\n","    mean_iu = np.nanmean(iu)\n","    freq = hist.sum(axis=1) / hist.sum()\n","    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n","    return acc, acc_cls, mean_iu, fwavacc"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"8n8Iee6WMMUR","executionInfo":{"status":"ok","timestamp":1620201829273,"user_tz":-540,"elapsed":39282,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def label_accuracy_score(hist):\n","    \"\"\"\n","    Returns accuracy score evaluation result.\n","      - [acc]: overall accuracy\n","      - [acc_cls]: mean accuracy\n","      - [mean_iu]: mean IU\n","      - [fwavacc]: fwavacc\n","    \"\"\"\n","    acc = np.diag(hist).sum() / hist.sum()\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        acc_cls = np.diag(hist) / hist.sum(axis=1)\n","    acc_cls = np.nanmean(acc_cls)\n","\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n","    mean_iu = np.nanmean(iu)\n","\n","    freq = hist.sum(axis=1) / hist.sum()\n","    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n","    return acc, acc_cls, mean_iu, fwavacc"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgU8J0coMMWX","executionInfo":{"status":"ok","timestamp":1620201829273,"user_tz":-540,"elapsed":38820,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def add_hist(hist, label_trues, label_preds, n_class):\n","    \"\"\"\n","        stack hist(confusion matrix)\n","    \"\"\"\n","\n","    for lt, lp in zip(label_trues, label_preds):\n","        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n","\n","    return hist"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQTFVol0RRnv","executionInfo":{"status":"ok","timestamp":1620201829273,"user_tz":-540,"elapsed":38478,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def rand_bbox(size, lam):\n","    W = size[2]\n","    H = size[3]\n","    cut_rat = np.sqrt(1.0 - lam)\n","    cut_w = np.int(W * cut_rat)\n","    cut_h = np.int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","    return bbx1, bby1, bbx2, bby2"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFMtLMfxPMIV","executionInfo":{"status":"ok","timestamp":1620201829274,"user_tz":-540,"elapsed":38001,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def cutmix(data, target, alpha):\n","    indices = torch.randperm(data.size(0))\n","    shuffled_data = data[indices]\n","    shuffled_target = target[indices]\n","\n","    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n","    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n","    new_data = data.clone()\n","    new_target = target.clone()\n","    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n","    new_target[:, bby1:bby2, bbx1:bbx2] = target[indices, bby1:bby2, bbx1:bbx2]\n","    # adjust lambda to exactly match pixel ratio\n","    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n","    \n","\n","    return new_data, new_target"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxlrGoiVMMY4","executionInfo":{"status":"ok","timestamp":1620201829275,"user_tz":-540,"elapsed":37604,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler):\n","    model.train()\n","    running_loss = None\n","    \n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n","\n","    for step, (imgs, masks) in pbar:\n","\n","        if (step+1) == (len(train_loader)):\n","            continue\n","        mix_decision = np.random.rand()\n","        imgs = torch.stack(imgs)\n","        masks = torch.stack(masks)\n","        imgs = imgs.to(device).float()\n","        masks = masks.to(device).long()\n","        \n","        if mix_decision < CFG['mix_prob']:\n","            imgs, masks = cutmix(imgs, masks, 1.0)\n","\n","        with autocast():\n","            model.to(device)\n","            mask_preds = model(imgs)\n","            loss = criterion(mask_preds, masks) / CFG['gradient_accumulation_steps']\n","            scaler.scale(loss).backward()\n","\n","            # loss.backward()\n","\n","            if running_loss is None:\n","                running_loss = loss.item() * CFG['gradient_accumulation_steps']\n","            else:\n","                running_loss = running_loss * 0.99 + loss.item() * CFG['gradient_accumulation_steps'] * 0.01\n","\n","            if ((step + 1) % CFG[\"gradient_accumulation_steps\"]==0) or ((step+1) == (len(train_loader))):\n","                scaler.step(optimizer)\n","                scaler.update()\n","                # optimizer.zero_grad()\n","                # optimizer.step()                            \n","                optimizer.zero_grad() \n","                description = f\"epoch {epoch} loss: {running_loss: .4f}\"\n","                pbar.set_description(description)\n","                \n","    scheduler.step()        "],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWRZ04KxMMbX","executionInfo":{"status":"ok","timestamp":1620201829275,"user_tz":-540,"elapsed":37213,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def valid_one_epoch(epoch, model, device, criterion, val_loader):\n","    model.eval()\n","    \n","    total_loss = 0\n","    running_loss = None\n","    cnt = 0\n","    mIoU_list = []\n","    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0, leave=True)\n","    hist = np.zeros((12, 12))\n","    for step, (imgs, masks) in pbar:\n","        if (step+1) == (len(train_loader)):\n","            continue\n","        imgs = torch.stack(imgs)\n","        masks = torch.stack(masks)\n","        imgs = imgs.to(device).float()\n","        masks = masks.to(device).long()\n","        \n","        cnt += 1\n","\n","        mask_preds = model(imgs)\n","        # print(f\"{mask_preds.shape}       \")\n","        loss = criterion(mask_preds, masks)\n","\n","        mask_preds = torch.argmax(mask_preds, dim=1).detach().cpu().numpy()\n","        # print(mask_preds.shape)\n","\n","        mIoU = label_accuracy_score_(masks.detach().cpu().numpy(), mask_preds, n_class=12)[2]\n","        mIoU_list.append(mIoU)\n","\n","        total_loss += loss.item()\n","            \n","        if running_loss is None:\n","            running_loss = loss.item()\n","        else:\n","            running_loss = running_loss * 0.99 + loss.item() * 0.01\n","\n","        description = f'epoch {epoch} Loss: {running_loss:.4f}, mIoU: {np.mean(mIoU_list):.4f}'\n","        pbar.set_description(description)\n","\n","    return total_loss/cnt, np.mean(mIoU_list)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uf1S2tfnMMdw","executionInfo":{"status":"ok","timestamp":1620201829275,"user_tz":-540,"elapsed":36863,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["FOLDS = 5\n","kf = KFold(FOLDS, shuffle=True, random_state=CFG['seed'])\n","df[\"Folds\"] = 0\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n","    df.loc[val_idx, 'Folds'] = fold"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vgls-tqKMS0V","executionInfo":{"status":"ok","timestamp":1620201829276,"user_tz":-540,"elapsed":36464,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERQDJsYZMS2o","executionInfo":{"status":"ok","timestamp":1620201829276,"user_tz":-540,"elapsed":35999,"user":{"displayName":"주영이","photoUrl":"","userId":"06973549239085587415"}}},"source":["def create_folder(directory):\n","    try:\n","        os.makedirs(directory)\n","    except:\n","        pass"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMzx6Tb8MS43","outputId":"de694746-26d6-4dd3-b8f9-30ae3718318a"},"source":["for fold in range(FOLDS):\n","    # if fold == 0 or fold == 1 or fold == 2:\n","    #   continue\n","    print(f\"{fold} fold start\")\n","    \n","    if CFG['decoder'] == \"Unetpp\":\n","        model = smp.UnetPlusPlus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n","    elif CFG['decoder'] == 'DeepLabV3Plus':\n","        model = smp.DeepLabV3Plus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n","    elif CFG['decoder'] == 'DeepLabV3':\n","        model = smp.DeepLabV3(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n","    elif CFG['decoder'] == \"UperNet\":\n","        model = encoding.models.sseg.UperNet(12, CFG['encoder'], aux=False)\n","    elif CFG['decoder'] == \"PSPNet\":\n","        model = smp.PSPNet(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n","    elif CFG['decoder'] == \"UneXt\":\n","        model = UneXt50()\n","    \n","    if CFG['scheduler'] == \"Warmup\":\n","        if CFG['optimizer'] == \"Adam\":\n","            optimizer = torch.optim.Adam(model.parameters(), lr=0, weight_decay=CFG['weight_decay'])\n","            scheduler = CustomCosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_max=CFG['lr'], T_up=CFG['epochs']//5, gamma=1.)\n","        elif CFG['optimizer'] == \"AdamW\":\n","            optimizer = torch.optim.AdamW(model.parameters(), lr=0, weight_decay=CFG['weight_decay'])\n","            scheduler = CustomCosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_max=CFG['lr'], T_up=CFG['epochs']//5, gamma=1.)\n","    else:\n","        if CFG['optimizer'] == \"Adam\":\n","            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n","    \n","    scaler = GradScaler()\n","    train_loader, valid_loader = prepare_dataloader(df, [fold])\n","    \n","    best_mIoU = 0\n","    num_epochs = CFG['epochs']\n","    \n","    for epoch in range(num_epochs):\n","        train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler)\n","\n","        with torch.no_grad():\n","            epoch_loss, mIoU = valid_one_epoch(epoch, model, device, criterion, valid_loader)\n","\n","        # neptune.log_metric(f\"fold{fold} epoch loss\", epoch_loss)\n","        # neptune.log_metric(f\"fold{fold} mIoU\", mIoU)\n","\n","        if best_mIoU < mIoU:\n","            best_mIoU = mIoU\n","            dir_ = f\"/content/drive/MyDrive/trash_segmentation/models\"\n","            create_folder(dir_)\n","            # torch.save({'model': model.state_dict(),\n","            #             'optimizer': optimizer.state_dict(),\n","            #             'scheduler': scheduler.state_dict()\n","            #             }, f\"{dir_}/{CFG['decoder']}_{CFG['encoder']}_{fold}.pth\")\n","            torch.save(model.state_dict(), f\"{dir_}/{CFG['decoder']}_{CFG['encoder']}_{fold}.pth\")\n","            print(\"model is saved\")\n","        print(\"\")\n","\n","    # neptune.log_metric(f\"fold {fold} Best mIoU\", best_mIoU)\n","    del model, optimizer, train_loader, valid_loader, scheduler\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","# neptune.stop()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 fold start\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/411 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","epoch 0 loss:  2.6758: 100%|██████████| 411/411 [02:29<00:00,  2.76it/s]\n","epoch 0 Loss: 2.7002, mIoU: 0.0128: 100%|██████████| 103/103 [00:18<00:00,  5.44it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 1 loss:  1.1143: 100%|██████████| 411/411 [02:26<00:00,  2.81it/s]\n","epoch 1 Loss: 0.8700, mIoU: 0.2394: 100%|██████████| 103/103 [00:19<00:00,  5.40it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 2 loss:  0.8944: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 2 Loss: 0.7692, mIoU: 0.3634: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 3 loss:  0.8199: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 3 Loss: 0.7320, mIoU: 0.4202: 100%|██████████| 103/103 [00:18<00:00,  5.57it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 4 loss:  0.7870: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 4 Loss: 0.7134, mIoU: 0.4472: 100%|██████████| 103/103 [00:18<00:00,  5.54it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 5 loss:  0.7578: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 5 Loss: 0.7216, mIoU: 0.4484: 100%|██████████| 103/103 [00:18<00:00,  5.53it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 6 loss:  0.7368: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 6 Loss: 0.7159, mIoU: 0.4798: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 7 loss:  0.7201: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 7 Loss: 0.6958, mIoU: 0.4792: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 8 loss:  0.7024: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 8 Loss: 0.6807, mIoU: 0.5017: 100%|██████████| 103/103 [00:18<00:00,  5.55it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 9 loss:  0.6803: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 9 Loss: 0.6828, mIoU: 0.5052: 100%|██████████| 103/103 [00:18<00:00,  5.53it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 10 loss:  0.6700: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 10 Loss: 0.6780, mIoU: 0.5163: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 11 loss:  0.6571: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 11 Loss: 0.6810, mIoU: 0.5184: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 12 loss:  0.6530: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 12 Loss: 0.6734, mIoU: 0.5080: 100%|██████████| 103/103 [00:18<00:00,  5.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 13 loss:  0.6369: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 13 Loss: 0.6787, mIoU: 0.5327: 100%|██████████| 103/103 [00:18<00:00,  5.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 14 loss:  0.6258: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 14 Loss: 0.6746, mIoU: 0.5260: 100%|██████████| 103/103 [00:18<00:00,  5.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 15 loss:  0.6234: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 15 Loss: 0.6644, mIoU: 0.5372: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 16 loss:  0.6132: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 16 Loss: 0.6598, mIoU: 0.5403: 100%|██████████| 103/103 [00:18<00:00,  5.48it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 17 loss:  0.6124: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 17 Loss: 0.6818, mIoU: 0.5361: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 18 loss:  0.6089: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 18 Loss: 0.6614, mIoU: 0.5469: 100%|██████████| 103/103 [00:18<00:00,  5.51it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 19 loss:  0.6027: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 19 Loss: 0.6599, mIoU: 0.5466: 100%|██████████| 103/103 [00:18<00:00,  5.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 20 loss:  0.6024: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 20 Loss: 0.6569, mIoU: 0.5498: 100%|██████████| 103/103 [00:18<00:00,  5.51it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 21 loss:  0.5984: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 21 Loss: 0.6581, mIoU: 0.5519: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 22 loss:  0.6009: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 22 Loss: 0.6579, mIoU: 0.5476: 100%|██████████| 103/103 [00:18<00:00,  5.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 23 loss:  0.5992: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 23 Loss: 0.6559, mIoU: 0.5504: 100%|██████████| 103/103 [00:18<00:00,  5.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 24 loss:  0.6024: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 24 Loss: 0.6563, mIoU: 0.5548: 100%|██████████| 103/103 [00:18<00:00,  5.43it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n","1 fold start\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 0 loss:  2.8699: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 0 Loss: 2.8826, mIoU: 0.0076: 100%|██████████| 103/103 [00:18<00:00,  5.55it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 1 loss:  1.1294: 100%|██████████| 411/411 [02:25<00:00,  2.83it/s]\n","epoch 1 Loss: 0.8825, mIoU: 0.2372: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 2 loss:  0.8725: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 2 Loss: 0.7645, mIoU: 0.4054: 100%|██████████| 103/103 [00:18<00:00,  5.51it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 3 loss:  0.7943: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 3 Loss: 0.7494, mIoU: 0.4435: 100%|██████████| 103/103 [00:18<00:00,  5.53it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 4 loss:  0.7751: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 4 Loss: 0.7644, mIoU: 0.4573: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 5 loss:  0.7657: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 5 Loss: 0.7603, mIoU: 0.4702: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 6 loss:  0.7249: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 6 Loss: 0.7640, mIoU: 0.4881: 100%|██████████| 103/103 [00:18<00:00,  5.53it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 7 loss:  0.7031: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 7 Loss: 0.7458, mIoU: 0.4886: 100%|██████████| 103/103 [00:18<00:00,  5.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 8 loss:  0.6938: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 8 Loss: 0.7591, mIoU: 0.4761: 100%|██████████| 103/103 [00:18<00:00,  5.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 9 loss:  0.6802: 100%|██████████| 411/411 [02:25<00:00,  2.82it/s]\n","epoch 9 Loss: 0.7470, mIoU: 0.5191: 100%|██████████| 103/103 [00:18<00:00,  5.48it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["model is saved\n","\n"],"name":"stdout"},{"output_type":"stream","text":["epoch 10 loss:  0.6759: 100%|██████████| 411/411 [02:26<00:00,  2.81it/s]\n","epoch 10 Loss: 0.7649, mIoU: 0.5188: 100%|██████████| 103/103 [00:19<00:00,  5.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","epoch 11 loss:  0.6488:  99%|█████████▊| 405/411 [02:24<00:02,  2.83it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8e6qIHMy6kQo"},"source":[""],"execution_count":null,"outputs":[]}]}