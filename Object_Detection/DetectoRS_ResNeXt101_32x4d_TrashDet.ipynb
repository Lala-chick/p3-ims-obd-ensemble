{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DetectoRS_ResNeXt101_32x4d_TrashDet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPpktVoPDkqb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVSmctk4Dvss",
        "outputId": "cf691676-2fc0-4431-ecff-41c32e7a9f6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOegtpPpKTf1"
      },
      "source": [
        "# Unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZglAhf1GHRfI"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Trash_obj/data_original.zip -d /content  # images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMfjxsMGWtfV"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Trash_obj/masks.zip -d /content  # masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqlD6bo-9lAb"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Trash_obj/new_image.zip -d /content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTIIMSfveAdN"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Trash_obj/new_mask.zip -d /content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0t4kr38_pd4"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Trash_obj/battery_plus.json.zip -d /content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D2ZoFcnCIUC"
      },
      "source": [
        "# Install Requierd Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fNCVfu8liT",
        "outputId": "f4740947-dadc-4772-ce7d-2d45309f93cd"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YzEl1MqCDMH"
      },
      "source": [
        "!pip install bottleneck-transformer-pytorch\n",
        "!pip install timm\n",
        "!pip install albumentations==0.4.6\n",
        "!pip install adamp\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.1/index.html\n",
        "!pip install mmdet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDR4jvDZOHq1"
      },
      "source": [
        "!pip uninstall pycocotools -y\n",
        "!pip install mmpycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7lSdfV3rOZJ"
      },
      "source": [
        "%cd /content/drive/MyDrive/Trash_obj/apex-master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lxPiNZmrPoC"
      },
      "source": [
        "!pip install -v --disable-pip-version-check --no-cache-dir ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlnv1GkKWzd"
      },
      "source": [
        "# cd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5GonOPsFnIo"
      },
      "source": [
        "%cd /content/drive/MyDrive/Trash_obj/UniverseNet-master/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4ruypB5TgIX"
      },
      "source": [
        "# BaseLine Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvrJTDY4CWYB"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXB9zmryTfzn"
      },
      "source": [
        "from mmcv import Config\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "from mmdet.datasets import (build_dataloader, build_dataset,\n",
        "                            replace_ImageToTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI0TWWISm_bH"
      },
      "source": [
        "!nvidia-smi --gpu-reset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1yYOGazDYWM"
      },
      "source": [
        "### Seed, Batch, Epoch, GPU set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bp0991wDXyJ"
      },
      "source": [
        "cfg.data.samples_per_gpu = 2 # Batch Size\n",
        "cfg.runner.max_epochs = 45 # Epochs\n",
        "cfg.seed=42 # Seed\n",
        "cfg.gpu_ids = [0] # GPU set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqKnBZJECcGe"
      },
      "source": [
        "### Class, Dataset set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzr51cURTejt"
      },
      "source": [
        "# Classes Set\n",
        "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
        "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
        "# config file 들고오기\n",
        "cfg = Config.fromfile('./configs/detectors/detectors_htc_r50_1x_coco.py')\n",
        "PREFIX = '/content/'\n",
        "cfg.data_root = PREFIX\n",
        "\n",
        "# dataset 바꾸기\n",
        "cfg.data.train.classes = classes\n",
        "cfg.data.train.img_prefix = PREFIX\n",
        "cfg.data.train.ann_file = PREFIX + 'battery_plus.json'\n",
        "# cfg.data.train.pipeline[2]['img_scale'] = (512, 512)\n",
        "\n",
        "cfg.data.val.classes = classes\n",
        "cfg.data.val.img_prefix = PREFIX\n",
        "cfg.data.val.ann_file = PREFIX + 'val.json'\n",
        "cfg.data.val.pipeline[1]['img_scale'] = (512, 512)\n",
        "\n",
        "cfg.data.test.classes = classes\n",
        "cfg.data.test.img_prefix = PREFIX\n",
        "cfg.data.test.ann_file = PREFIX + 'test.json'\n",
        "cfg.data.test.pipeline[1]['flip'] = True\n",
        "cfg.data.test.pipeline[1]['img_scale'] = [(256, 256),(320, 320),(384, 384),(448, 448),\n",
        "                      (512, 512),(576, 576),(640, 640),(704, 704),(768, 768)]\n",
        "\n",
        "# Mask, BBox classes 설정\n",
        "cfg.model.roi_head.mask_head[0]['num_classes'] = 11\n",
        "cfg.model.roi_head.mask_head[1]['num_classes'] = 11\n",
        "cfg.model.roi_head.mask_head[2]['num_classes'] = 11\n",
        "\n",
        "cfg.model.roi_head.bbox_head[0]['num_classes'] = 11\n",
        "cfg.model.roi_head.bbox_head[1]['num_classes'] = 11\n",
        "cfg.model.roi_head.bbox_head[2]['num_classes'] = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62sIVwqUD9Ou"
      },
      "source": [
        "### Model, Neck BackBone Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKBEYtQWCReD"
      },
      "source": [
        "# Model BackBone\n",
        "cfg.model.pretrained='open-mmlab://resnext101_32x4d' # 32 or 64\n",
        "cfg.model.backbone=dict(\n",
        "        type='DetectoRS_ResNeXt',\n",
        "        # pretrained='open-mmlab://resnext101_32x4d', # 32 or 64\n",
        "        depth=101,\n",
        "        groups=32, # 32 or 64\n",
        "        base_width=4,\n",
        "        num_stages=4,\n",
        "        out_indices=(0,1,2,3),\n",
        "        frozen_stages=1,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        norm_eval=True,\n",
        "        conv_cfg=dict(type='ConvAWS'),\n",
        "        sac=dict(type='SAC', use_deform=True),\n",
        "        stage_with_sac=(False, True, True, True),\n",
        "        output_img=True,\n",
        "        style='pytorch')\n",
        "\n",
        "# Neck BackBone\n",
        "cfg.model.neck=dict(\n",
        "        type='RFP',\n",
        "        rfp_steps=2,\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5,\n",
        "        aspp_out_channels=64,\n",
        "        aspp_dilations=(1, 3, 6, 1),\n",
        "        rfp_backbone=dict(\n",
        "            rfp_inplanes=256,\n",
        "            type='DetectoRS_ResNeXt',\n",
        "            depth=101,\n",
        "            groups=32, # 32 or 64\n",
        "            base_width=4,\n",
        "            num_stages=4,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "            frozen_stages=1,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            norm_eval=True,\n",
        "            conv_cfg=dict(type='ConvAWS'),\n",
        "            sac=dict(type='SAC', use_deform=True),\n",
        "            stage_with_sac=(False, True, True, True),\n",
        "            pretrained='open-mmlab://resnext101_32x4d', # 32 or 64\n",
        "            style='pytorch'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1PpY39jEW_-"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEpgZ85TCE6k"
      },
      "source": [
        "# Albumentation Augmentations\n",
        "cfg.albu_train_transforms = [\n",
        "    dict(\n",
        "        type='VerticalFlip',\n",
        "        p=0.5),\n",
        "    dict(\n",
        "        type='RandomRotate90'),\n",
        "]\n",
        "\n",
        "# Train Pipeline\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    # Multi Scale, Random Crop Training\n",
        "    dict(type='AutoAugment',\n",
        "         policies=[\n",
        "             [\n",
        "                 dict(type='Resize',\n",
        "                      img_scale=[(512, 512),(576, 576),(640, 640),(704, 704),(768, 768)],\n",
        "                      multiscale_mode='value',\n",
        "                      keep_ratio=True)\n",
        "             ],\n",
        "             [\n",
        "                 dict(type='Resize',\n",
        "                      img_scale=[(512, 512), (768, 768)],\n",
        "                      multiscale_mode='value',\n",
        "                      keep_ratio=True),\n",
        "                 dict(type='RandomCrop',\n",
        "                      crop_type='absolute_range',\n",
        "                      crop_size=(384, 384),\n",
        "                      allow_negative_crop=True),\n",
        "                 dict(type='Resize',\n",
        "                      img_scale=[(512, 512),(576, 576),(640, 640),(704, 704),(768, 768)],\n",
        "                      multiscale_mode='value',\n",
        "                      override=True,\n",
        "                      keep_ratio=True)\n",
        "             ]\n",
        "         ]),\n",
        "    dict(type='Pad', size_divisor=32),\n",
        "    # Albumentation Augmentations, Get config from 'albu_train_transforms'\n",
        "    dict(\n",
        "        type='Albu',\n",
        "        transforms=albu_train_transforms,\n",
        "        bbox_params=dict(\n",
        "            type='BboxParams',\n",
        "            format='pascal_voc',\n",
        "            label_fields=['gt_labels'],\n",
        "            min_visibility=0.0,\n",
        "            filter_lost_elements=True),\n",
        "        keymap={\n",
        "            'img': 'image',\n",
        "            'gt_masks': 'masks',\n",
        "            'gt_bboxes': 'bboxes'\n",
        "        },\n",
        "        update_pad_shape=False,\n",
        "        skip_img_without_anno=True),\n",
        "    dict(type='Normalize', **img_norm_cfg),\n",
        "    dict(type='SegRescale', scale_factor=1 / 8),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks', 'gt_semantic_seg']),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_IrbyzTCyw-"
      },
      "source": [
        "### LR, Scheduler, Optimizer set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nJw-CB9CIBm"
      },
      "source": [
        "# Scheduler\n",
        "cfg.lr_config = dict(\n",
        "  policy='CosineAnnealing',\n",
        "  min_lr=1e-10,\n",
        "  warmup='linear',\n",
        "  warmup_iters=5,\n",
        "  warmup_ratio=1e-10,\n",
        "  warmup_by_epoch=True\n",
        ")\n",
        "\n",
        "# Optimizer, lr\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)\n",
        "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
        "\n",
        "# Hook\n",
        "cfg.fp16 = None\n",
        "cfg.optimizer_config = dict(\n",
        "    type='ApexOptimizerHook',\n",
        "    # Batch size x Update Interval = Normalize Term\n",
        "    update_interval=4,\n",
        "    grad_clip=None,\n",
        "    coalesce=True,\n",
        "    bucket_size_mb=-1,\n",
        "    use_fp16=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46k-26n5DH0U"
      },
      "source": [
        "### Resume Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWVgGt6aDF2C"
      },
      "source": [
        "cfg.resume_from = '/content/drive/MyDrive/Trash_obj/UniverseNet-master/work_dirs/detectors/DetectoRS_mstrain_400_1200_x101_64x4d_40e/epoch_28.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhNgLph7FrZH"
      },
      "source": [
        "# Initialize Model, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcK1DkUHTeni"
      },
      "source": [
        "model = build_detector(cfg.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPW5ditKTepN"
      },
      "source": [
        "datasets = [build_dataset(cfg.data.train)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9mHLzWsF3RV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPPWvV9WTesF"
      },
      "source": [
        "train_detector(model, datasets[0], cfg, distributed=False, validate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffcT4A4YF-ol"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28kDn3m_vCk3",
        "outputId": "afd540b5-011a-445c-b1b4-4b738e260a08"
      },
      "source": [
        "%cd /content/drive/MyDrive/Trash_obj/UniverseNet-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Trash_obj/UniverseNet-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDigJyKeGas3"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKMtXJLFTeu2"
      },
      "source": [
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmdet.datasets import (build_dataloader, build_dataset,\n",
        "                            replace_ImageToTensor)\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import single_gpu_test\n",
        "from mmcv.runner import load_checkpoint\n",
        "import os\n",
        "from mmcv.parallel import MMDataParallel\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEaLBXZWG0cK"
      },
      "source": [
        "### Seed, Batch, Epoch, GPU set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2WlROxBG0DM"
      },
      "source": [
        "cfg.data.samples_per_gpu = 4 \n",
        "epoch = 45 # Epoch which Weight to Inference\n",
        "cfg.seed=42\n",
        "cfg.gpu_ids = [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bS6yyHrGeRZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAQ_3qczTexu"
      },
      "source": [
        "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
        "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
        "# config file 들고오기\n",
        "cfg = Config.fromfile('./configs/detectors/detectors_htc_r50_1x_coco.py')\n",
        "\n",
        "PREFIX = '/content/'\n",
        "\n",
        "# dataset 바꾸기\n",
        "cfg.data.train.classes = classes\n",
        "cfg.data.train.img_prefix = PREFIX\n",
        "cfg.data.train.ann_file = PREFIX + 'train.json'\n",
        "# cfg.data.train.pipeline[2]['img_scale'] = (512, 512)\n",
        "\n",
        "cfg.data.val.classes = classes\n",
        "cfg.data.val.img_prefix = PREFIX\n",
        "cfg.data.val.ann_file = PREFIX + 'val.json'\n",
        "cfg.data.val.pipeline[1]['img_scale'] = (512, 512)\n",
        "\n",
        "cfg.data.test.classes = classes\n",
        "cfg.data.test.img_prefix = PREFIX\n",
        "cfg.data.test.ann_file = PREFIX + 'test.json'\n",
        "cfg.data.test.pipeline[1]['flip'] = True\n",
        "# TTA Multi Scales\n",
        "cfg.data.test.pipeline[1]['img_scale'] = [(512, 512),(576, 576),(640, 640),(704, 704),(768, 768)]\n",
        "\n",
        "# Set Model same as trained\n",
        "cfg.model.pretrained='open-mmlab://resnext101_32x4d'\n",
        "cfg.model.backbone=dict(\n",
        "        type='DetectoRS_ResNeXt',\n",
        "        # pretrained='open-mmlab://resnext101_32x4d',\n",
        "        depth=101,\n",
        "        groups=32,\n",
        "        base_width=4,\n",
        "        num_stages=4,\n",
        "        out_indices=(0,1,2,3),\n",
        "        frozen_stages=1,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        norm_eval=True,\n",
        "        conv_cfg=dict(type='ConvAWS'),\n",
        "        sac=dict(type='SAC', use_deform=True),\n",
        "        stage_with_sac=(False, True, True, True),\n",
        "        output_img=True,\n",
        "        style='pytorch')\n",
        "\n",
        "cfg.model.neck=dict(\n",
        "        type='RFP',\n",
        "        rfp_steps=2,\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5,\n",
        "        aspp_out_channels=64,\n",
        "        aspp_dilations=(1, 3, 6, 1),\n",
        "        rfp_backbone=dict(\n",
        "            rfp_inplanes=256,\n",
        "            type='DetectoRS_ResNeXt',\n",
        "            depth=101,\n",
        "            groups=32,\n",
        "            base_width=4,\n",
        "            num_stages=4,\n",
        "            out_indices=(0, 1, 2, 3),\n",
        "            frozen_stages=1,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            norm_eval=True,\n",
        "            conv_cfg=dict(type='ConvAWS'),\n",
        "            sac=dict(type='SAC', use_deform=True),\n",
        "            stage_with_sac=(False, True, True, True),\n",
        "            pretrained='open-mmlab://resnext101_32x4d',\n",
        "            style='pytorch'))\n",
        "\n",
        "# Saved Directory\n",
        "cfg.work_dir = './work_dirs/detectors/DetectoRS_mstrain_400_1200_x101_64x4d_40e'\n",
        "\n",
        "# Same as Trained\n",
        "cfg.model.roi_head.mask_head[0]['num_classes'] = 11\n",
        "cfg.model.roi_head.mask_head[1]['num_classes'] = 11\n",
        "cfg.model.roi_head.mask_head[2]['num_classes'] = 11\n",
        "\n",
        "cfg.model.roi_head.bbox_head[0]['num_classes'] = 11\n",
        "cfg.model.roi_head.bbox_head[1]['num_classes'] = 11\n",
        "cfg.model.roi_head.bbox_head[2]['num_classes'] = 11\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)\n",
        "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
        "cfg.model.train_cfg = None\n",
        "\n",
        "# checkpoint path\n",
        "checkpoint_path = os.path.join(cfg.work_dir, f'epoch_{epoch}.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj3IsbUKHqPW"
      },
      "source": [
        "### Set Dataset, Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfZwSv-yTe1D"
      },
      "source": [
        "dataset = build_dataset(cfg.data.test)\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        samples_per_gpu=1,\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaJ7uKyjTe27"
      },
      "source": [
        "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
        "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
        "\n",
        "model.CLASSES = dataset.CLASSES\n",
        "model = MMDataParallel(model.cuda(), device_ids=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EXYqatXHvo7"
      },
      "source": [
        "### Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfvyqBYeTe5r"
      },
      "source": [
        "output = single_gpu_test(model, data_loader, show_score_thr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CAzzIADIOtx"
      },
      "source": [
        "### Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "BtiWPgtlTe8J",
        "outputId": "736fac69-423e-475b-baf3-775d5cdb9be2"
      },
      "source": [
        "prediction_strings = []\n",
        "file_names = []\n",
        "coco = COCO(cfg.data.test.ann_file)\n",
        "imag_ids = coco.getImgIds()\n",
        "\n",
        "class_num = 11\n",
        "for i, out in enumerate(output):\n",
        "    prediction_string = ''\n",
        "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
        "    for j in range(class_num):\n",
        "        # 1 stage model = for o in out[j]:\n",
        "        # 2 stage model Segmentation = for o in out[1][j]:\n",
        "        # 2 stage model Detection\n",
        "        for o in out[0][j]:\n",
        "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
        "                o[2]) + ' ' + str(o[3]) + ' '\n",
        "        \n",
        "    prediction_strings.append(prediction_string)\n",
        "    file_names.append(image_info['file_name'])\n",
        "\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['PredictionString'] = prediction_strings\n",
        "submission['image_id'] = file_names\n",
        "\n",
        "# Submission File Name set\n",
        "submission.to_csv(os.path.join(cfg.work_dir, f'submission_DetectoRS_ResNeXt101_Final_{epoch}.csv'), index=None)\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PredictionString</th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0 0.0012175218 268.1394 0.09808382 324.08347 3...</td>\n",
              "      <td>batch_01_vt/0021.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0 0.005388239 286.18134 340.91245 308.2169 376...</td>\n",
              "      <td>batch_01_vt/0028.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1 0.99937457 71.53811 170.43152 373.08047 377....</td>\n",
              "      <td>batch_01_vt/0031.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0 0.0011801156 0.038686067 226.98409 34.433064...</td>\n",
              "      <td>batch_01_vt/0032.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0 0.03611503 38.37911 460.02594 76.998695 472....</td>\n",
              "      <td>batch_01_vt/0070.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    PredictionString              image_id\n",
              "0  0 0.0012175218 268.1394 0.09808382 324.08347 3...  batch_01_vt/0021.jpg\n",
              "1  0 0.005388239 286.18134 340.91245 308.2169 376...  batch_01_vt/0028.jpg\n",
              "2  1 0.99937457 71.53811 170.43152 373.08047 377....  batch_01_vt/0031.jpg\n",
              "3  0 0.0011801156 0.038686067 226.98409 34.433064...  batch_01_vt/0032.jpg\n",
              "4  0 0.03611503 38.37911 460.02594 76.998695 472....  batch_01_vt/0070.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4NvWvC7TfAH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}